---
title: "Logistic Regression"
author: "F.A. Barrios<br><small>UNAM<br></small>"
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
    highlight: kate
---

```{r setup, include=FALSE}
## Global options
knitr::opts_chunk$set(cache = TRUE)
```

```{r}
library(tidyverse)
library(HSAUR2)
library(effects)
library(modelsummary)

```

# Logistic Regression  


"Odds: the chances of something happening"  
 Odds provide a measure of the likelihood of a particular outcome.  
 
*odds of an outcome   - ratio of the number of events that produce the outcome to  
                      to the number that do not.*  
                      
The binary logistic regression model studies how a set of predictor variables $X$ is related to a dichotomous response variable $Y$.  We will define the response to be $Y = 0$ or $1$, with $Y = 1$ denoting the occurrence of the event of interest.  
A linear attempt to model a vector $X$ of predictors $\{ X_1, X_2, \dots , X_k \}$ will look like:  
$$ E[Y|X] = X\beta$$  
since the expectation $E[Y|X]$ of a binary variable $Y$ is $Prob\{Y=1|X\}$. A purely linear model like this cannot easily fit the data over the whole range.  Therefore the statistically preferred model for the analysis of binary responses is instead the binary logistic regression model, stated in terms of the probability that $Y=1$ given $X$:  
$$ Prob\{Y=1 | X\} = [1+ \exp(-X\beta)]^{-1}$$.  
with $X\beta$ equal to $\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_k X_k$. The function  
$$ P = [1 + \exp(-x)]^{-1} $$  
```{r}
# Logistic function
# plot of the logistic function

f_logistic <- function(x) {
  return (1/(1 + exp(-x)))
  }
  
curve(f_logistic,
  from = -4, 
  to = 4,
  ylab = "P",
  xlab = "X",
  main = "Logistic Function")
```

is called the logistic function, has unlimited range for $x$ while $P$ is restricted to range from $0$ to $1$. Using $1 - P = \exp(-x)/[1 + \exp(-x)]$ we can solve teh equation of the logistic for $x$ which is the inverse of the logistic function:  
$$ x = \log[\frac{P}{1-P}] = \log[odds \space that \space Y=1 \space occurs] = logit\{Y=1\}$$  
The logistic model is a direct probability model since it is stated in terms of $Prob[Y=1 | X]$.  

## Model Assumptions  
Since the distribution of a binary random variable $Y$ is defined by the true probability that $Y=1$ and since the model makes no assumption about the distribution of the predictors, the logistic model makes no assumption about distributions. Its only assumptions relate to the form of the regression equation, and are easily understood if transforming $Prob\{Y=1\}$ to a model linear in $X\beta$:  

$$ \tt logit\{Y=1 | X\} = logit(P) = \log[\frac{P}{1-P}] = X \beta$$
where $ P = Prob\{Y=1 | X\}$ the model is a linear regression model in le log odds that $Y=1$ since $ \\tt logit(P)$ is a weighted sum of the $Xs$,

$$ \tt logit\{Y=1|X\} = \beta_0 + \beta_1 X_1 + \dots + \beta_j X_j + \dots + \beta_k X_k$$
$$ = \beta_j X_j + C$$
where all other factors are held constant, $C$ is a constant given by  
$$ C = \beta_0 + \beta_1 X_1 + \dots + \beta_{j-1}X_{j-1} + \beta_{j+1} X_{j+1} + \dots + \beta_k X_k $$  
Therefore the parameter $\beta_j$ is the change in the *log odds* per unit change in $X_j$ if $X_j$ represents a single factor that is linear and does not interact with other factors and if all the other factors are held constant. We can write the result in terms or the *odds that Y = 1*:
$$ \tt odds\{Y=1 | X\} = exp(X\beta) $$
and if all factors other than $X_j$ are held constant,

$$ \tt odds\{Y=1 | X\} = \exp(B_j X_j + C) = \exp(\beta_j X_j) \exp(C) $$
The regression parameters can also be written in terms of *odds ratios*. The odds that $Y = 1$ when $X_j$ is increased by $d$, divided by the odds at $X_j$ is  
$$ \frac{ odds\{Y=1 | X_1, \dots, X_j+d, \dots, X_k\}}{odds\{Y=1 | X_1, \dots, X_j,\dots, X_k \}} $$  
$$ = \frac{\exp[\beta_j(X_j+d)]\exp(C)}{\exp[\beta_j X_j]\exp(C)} $$  
$$ = \exp[\beta_j X_j + \beta_j d - \beta_j X_j] = \exp(\beta_j d)$$
The effect of increasing $X_j$ by $d$ is to increase the odds that $Y = 1$ by a factor of $\exp(\beta_j d)$, or to increase the $\log \space odds$ that $ Y = 1$ by an increment of $\beta_j d$.

## Interpretation of Regression Coefficients  
```{r}
wcgs <- read_csv("https://raw.githubusercontent.com/fabarrios/Regression/master/DataRegressBook/Chap2/wcgs.csv",
        show_col_types = FALSE)
```

To estimate a logistic regression model the general formula in the predictor variables is given by :    

$$log[\frac{\hat\mu(X)}{1-\hat\mu(X)}] = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_k X_k$$

If exponentiate both sides of the equation, we get  

$$\frac{\hat\mu(X)}{1-\hat\mu(X)} = exp(\beta_0) \times exp(\beta_1 X_1) \times exp(\beta_2 X_2) \times \cdots \times exp(\beta_k X_k)$$  

where the left hand of the equation, $\frac{\hat\mu(x)}{1-\hat\mu(x)}$, gives the *fitted odds* of success, **the fitted probability of success divided by the fitted probability of failure**. Exponentiating the model removes the logarithms and changes the model in the log-odds scale to one that is multiplicative, in this log odds scale.      
For the WCGS data and the variable Corollary Heart Disease (CHD) and age, the $\beta_1$ is the age slope of the fitted logistic model. The outcome of the model is the log odds of Corollary Heart Disease risk and the relationship with age, the slope coefficient $\beta_1$ gives the change in the log odds of chd69 associated with the model, chd69 is the presence of a cardio-vacular event (1).  

```{r}
wcgs <- mutate(wcgs, chd69 = factor(chd69))

# For table 5.2
CHD_glm01 <- glm(chd69 ~ age, data = wcgs, family = binomial())
summary(CHD_glm01)

# confint(CHD_glm01, parm = "age")
# To estimate the model
exp(coef(CHD_glm01)["age"])
```

The "link transformation" is the exponentiation, to obtain the odds of *Y*.  

## Example from HSAUR  

### Introduction  

The erythrocyte sedimentation rate (ESR) is the rate at which red blood cells (erythrocytes) settle out of suspension in the blood plasma, when measured under standard conditions.  If the ESR increases when the level of certain proteins in the blood plasma rise in association with conditions such as rheumatic diseases, chronic infections, and malignant diseases, its determination might be useful in screening blood samples taken from people suspected of suffering from one of the conditions mentioned. The absolute value of the ESR is not of great importance; rather, less than 20mm/hr indicates a 'healthy' individual. To asses whether the ESR is a useful diagnostic tool, Collett and Jemain (1985) collected the data in HSAUR. The question of interest is whether there is any association between the probability of an ESR reading greater than 20mm/hr and the levels of the two plasma proteins. If there is not then the determination of ESR would not be useful for diagnostic purposes.  

```{r}
# Using plasma data from HSAUR
data("plasma", package = "HSAUR2")
layout(matrix(1:2, ncol = 2))
# cdplot computes and plots conditional densities describing how the 
# conditional distribution of a categorical variable Y changes over 
# a numerical variable x

cdplot(ESR ~ fibrinogen, data = plasma)
cdplot(ESR ~ globulin, data = plasma)
```

To estimate a logistic regression model in R the glm (General Linear Model) is used, for binomial distribution the glm() function default to a logistic model.  

```{r}
# glm general linear model default is logistic for binomial distribution

plasma_glm01 <- glm(ESR ~ fibrinogen, data = plasma, family = binomial())
summary(plasma_glm01)
modelsummary(plasma_glm01)
```

From these results we see that the regression coefficients for fibrinogen is significant at the 5% level. An increase of one unit in this variable increases the log-odds on favor of an ESR value greater then 20 by estimated 1.83 with 95% confidence interval:  

```{r}
# coeff fibrinogen is sifnificative 5% one unit change in this variable 
# increases the log-odds in favor of ESR > 20mm/hr by 1.83

confint(plasma_glm01, parm = "fibrinogen")
exp(coef(plasma_glm01)["fibrinogen"])
exp(confint(plasma_glm01, parm = "fibrinogen"))
```
These are the values of the odds themselves (by exponentiating the estimate). So **increased values of fibrinogen lead to a grater probability of an ESR value greater than 20**.  

```{r}
# full model with two variables
plasma_glm02 <- glm(ESR ~ fibrinogen + globulin, data = plasma, family = binomial())
summary(plasma_glm02)
```

Comparing the residual deviance of the datasummary_correlation(dat)models: residual deviance 01: 24.84 residual deviance 02: 22.971 -> 1.869 (1.87), to test for significance R take the lgm with a $\chi^2$ the 1.87 we conclude that **the globulin has no influence in the ESR**.  
To compare the two nested models (with fibrinogen and fibrinogen + gamma globulin) we can estimate the ANOVA of the models (Pr of 0.1716)  

```{r}
anova(plasma_glm01, plasma_glm02, test = "Chisq")
anova(plasma_glm01)

# Estimates conditional probability of a ESR > 20 for all observations

prob <- predict(plasma_glm02, type = "response")
layout(matrix(1:1, ncol = 1))

plot(globulin ~ fibrinogen, data = plasma, xlim = c(2, 6), ylim = c(25, 55), pch = ".")
symbols(plasma$fibrinogen, plasma$globulin, circles = prob, add = TRUE)

plot(predictorEffects(plasma_glm02))
```

